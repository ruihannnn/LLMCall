2025-07-18 19:02:01,651 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:02:01,651 [ERROR] __main__: 执行失败: module 'response_processor' has no attribute ''
Traceback (most recent call last):
  File "C:\开源代码\LLMCall\main.py", line 115, in main
    chat_llm = init_chat_llm()
  File "C:\开源代码\LLMCall\main.py", line 55, in init_chat_llm
    response_processors = [getattr(response_processor, name) for name in response_processor_names]
  File "C:\开源代码\LLMCall\main.py", line 55, in <listcomp>
    response_processors = [getattr(response_processor, name) for name in response_processor_names]
AttributeError: module 'response_processor' has no attribute ''
2025-07-18 19:03:24,489 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:03:24,492 [ERROR] __main__: 执行失败: module 'response_processor' has no attribute ''
Traceback (most recent call last):
  File "C:\开源代码\LLMCall\main.py", line 115, in main
    chat_llm = init_chat_llm()
  File "C:\开源代码\LLMCall\main.py", line 55, in init_chat_llm
    response_processors = [getattr(response_processor, name) for name in response_processor_names]
  File "C:\开源代码\LLMCall\main.py", line 55, in <listcomp>
    response_processors = [getattr(response_processor, name) for name in response_processor_names]
AttributeError: module 'response_processor' has no attribute ''
2025-07-18 19:03:41,307 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:04:11,401 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer']
2025-07-18 19:04:11,402 [ERROR] dataset_config: 输入文件不存在: input
2025-07-18 19:04:30,033 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:04:35,752 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer']
2025-07-18 19:04:35,752 [ERROR] dataset_config: 输入文件不存在: input
2025-07-18 19:04:35,753 [ERROR] __main__: 执行失败: 输入文件不存在: input
Traceback (most recent call last):
  File "c:\开源代码\LLMCall\main.py", line 115, in main
    chat_llm = init_chat_llm()
  File "c:\开源代码\LLMCall\main.py", line 77, in init_chat_llm
    dataset_config = DatasetConfig(
  File "c:\开源代码\LLMCall\dataset_config.py", line 47, in __init__
    self._validate()
  File "c:\开源代码\LLMCall\dataset_config.py", line 58, in _validate
    raise ValueError(f"输入文件不存在: {self.input_path}")
ValueError: 输入文件不存在: input
2025-07-18 19:05:29,341 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:05:29,341 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer']
2025-07-18 19:05:29,341 [INFO] chat_llm: 初始化ChatLLM，URL: https://api.deepseek.com/v1
2025-07-18 19:05:29,341 [INFO] chat_llm: Prompt Keys: ['generate_assistant_new']
2025-07-18 19:05:29,341 [INFO] chat_llm: Response Processors: ['no_think_response_processor']
2025-07-18 19:05:29,707 [INFO] __main__: 开始处理: input.jsonl -> output.jsonl
2025-07-18 19:05:29,708 [ERROR] __main__: 执行失败: [WinError 3] 系统找不到指定的路径。: ''
Traceback (most recent call last):
  File "C:\开源代码\LLMCall\main.py", line 119, in main
    chat_llm.process_dataset()
  File "C:\开源代码\LLMCall\chat_llm.py", line 332, in process_dataset
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
  File "C:\Users\asus\AppData\Roaming\uv\python\cpython-3.10.18-windows-x86_64-none\lib\os.py", line 225, in makedirs
    mkdir(name, mode)
FileNotFoundError: [WinError 3] 系统找不到指定的路径。: ''
2025-07-18 19:06:37,745 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:06:37,745 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer']
2025-07-18 19:06:37,745 [INFO] chat_llm: 初始化ChatLLM，URL: https://api.deepseek.com/v1
2025-07-18 19:06:37,745 [INFO] chat_llm: Prompt Keys: ['generate_assistant_new']
2025-07-18 19:06:37,746 [INFO] chat_llm: Response Processors: ['no_think_response_processor']
2025-07-18 19:06:37,786 [INFO] __main__: 开始处理: C:\开源代码\LLMCall\input.jsonl -> C:\开源代码\LLMCall
2025-07-18 19:06:37,822 [INFO] chat_llm: 开始处理文件：C:\开源代码\LLMCall\input.jsonl
2025-07-18 19:06:42,130 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,131 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,132 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,133 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,135 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,136 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,137 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,142 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,146 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,146 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,147 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,149 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,150 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,152 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,155 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,155 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,157 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,158 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,159 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,160 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,184 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,185 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,198 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,199 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,199 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,200 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,215 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,215 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,216 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,217 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,217 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,217 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,217 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,220 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,220 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,222 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,223 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,224 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,230 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,231 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,233 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,233 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,259 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,259 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,260 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,261 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,271 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,273 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,274 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,279 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,280 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,281 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,285 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,285 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,286 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,288 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,290 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,296 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,303 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,307 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,317 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,320 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,322 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,325 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,326 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,331 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,336 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,336 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,343 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,344 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,364 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,365 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,370 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,371 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,371 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,373 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,374 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,376 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,392 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,395 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,395 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,398 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,399 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,401 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,402 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,404 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,405 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,405 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,406 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,406 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,408 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,410 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,411 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,415 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,415 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,417 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,418 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,418 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,442 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,444 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,446 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,447 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,447 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,448 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,451 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,453 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,454 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,468 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:06:42,469 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:06:42,470 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:06:42,471 [ERROR] __main__: 执行失败: [Errno 13] Permission denied: 'C:\\开源代码\\LLMCall'
Traceback (most recent call last):
  File "C:\开源代码\LLMCall\main.py", line 119, in main
    chat_llm.process_dataset()
  File "C:\开源代码\LLMCall\chat_llm.py", line 362, in process_dataset
    self.produce_data(data_rows, actual_output, pbar)
  File "C:\开源代码\LLMCall\chat_llm.py", line 218, in produce_data
    with open(output_path, "a", encoding="utf-8") as f:
PermissionError: [Errno 13] Permission denied: 'C:\\开源代码\\LLMCall'
2025-07-18 19:07:43,630 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:07:43,630 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer']
2025-07-18 19:07:43,630 [INFO] chat_llm: 初始化ChatLLM，URL: https://api.deepseek.com/v1
2025-07-18 19:07:43,630 [INFO] chat_llm: Prompt Keys: ['generate_assistant_new']
2025-07-18 19:07:43,630 [INFO] chat_llm: Response Processors: ['no_think_response_processor']
2025-07-18 19:07:43,669 [INFO] __main__: 开始处理: C:\\开源代码\\LLMCall\\data\\input.jsonl -> C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:07:43,700 [INFO] chat_llm: 开始处理文件：C:\\开源代码\\LLMCall\\data\\input.jsonl
2025-07-18 19:07:44,127 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,129 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,131 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,131 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,132 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,132 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,132 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,133 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,134 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,134 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,135 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,135 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,135 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,135 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,136 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,138 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,139 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,140 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,141 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,144 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,179 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,180 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,185 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,185 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,197 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,198 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,198 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,199 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,200 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,200 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,202 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,204 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,207 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,207 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,208 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,209 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,209 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,210 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,211 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,214 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,227 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,228 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,237 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,238 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,248 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,248 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,252 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,253 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,260 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,262 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,272 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,273 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,273 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,274 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,275 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,276 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,294 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,296 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,297 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,298 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,301 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,303 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,305 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,306 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,307 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,315 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,319 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,323 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,331 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,334 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,339 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,340 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,342 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,343 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,346 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,349 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,369 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,370 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,371 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,371 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,372 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,373 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,374 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,374 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,374 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,374 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,378 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,379 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,383 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,384 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,385 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,385 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,385 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,387 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,387 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,388 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,388 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,389 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,389 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,389 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,398 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,398 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,400 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,401 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,401 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,401 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,401 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,402 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,406 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,407 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,407 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,408 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,428 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,429 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/v1/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:07:44,429 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,431 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:07:44,431 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,431 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:07:44,431 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,432 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:07:44,433 [INFO] chat_llm: 处理完成: C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:07:44,433 [INFO] __main__: 处理完成，用时: 0.76秒
2025-07-18 19:08:09,257 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:08:09,257 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer']
2025-07-18 19:08:09,257 [INFO] chat_llm: 初始化ChatLLM，URL: https://api.deepseek.com
2025-07-18 19:08:09,259 [INFO] chat_llm: Prompt Keys: ['generate_assistant_new']
2025-07-18 19:08:09,259 [INFO] chat_llm: Response Processors: ['no_think_response_processor']
2025-07-18 19:08:09,297 [INFO] __main__: 开始处理: C:\\开源代码\\LLMCall\\data\\input.jsonl -> C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:08:09,333 [INFO] chat_llm: 开始处理文件：C:\\开源代码\\LLMCall\\data\\input.jsonl
2025-07-18 19:08:09,744 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,746 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,748 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,748 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,748 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,748 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,749 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,750 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,751 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,752 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,754 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,755 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,766 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,766 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,767 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,768 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,769 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,771 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,784 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,784 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,790 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,791 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,803 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,804 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,805 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,806 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,807 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,808 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,808 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,810 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,820 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,821 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,825 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,825 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,826 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,827 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,827 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,828 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,837 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,838 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,840 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,840 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,856 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,856 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,865 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,867 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,867 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,870 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,871 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,871 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,872 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,877 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,878 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,879 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,882 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,883 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,883 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,888 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,889 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,892 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,897 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,902 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,910 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,910 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,919 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,920 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,923 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,923 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,927 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,928 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,929 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,930 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,938 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,940 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,944 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,946 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,947 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:09,947 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:09,948 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,950 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,953 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,954 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,958 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,961 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,967 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,968 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,970 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,971 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,971 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,971 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:09,972 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,972 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:09,973 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:09,973 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:09,973 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:09,974 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:09,980 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,982 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,982 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:09,982 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:09,983 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,985 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,985 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:09,986 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:09,993 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:09,995 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:09,995 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:09,995 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:10,001 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:10,003 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:10,005 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:10,007 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:10,008 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:10,009 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:10,010 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:10,011 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:10,014 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 400 Bad Request"
2025-07-18 19:08:10,018 [ERROR] chat_llm: LLM调用失败: Error code: 400 - {'error': {'message': 'Invalid max_tokens value, the valid range of max_tokens is [1, 8192]', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_request_error'}}
2025-07-18 19:08:10,019 [WARNING] chat_llm: 无法生成有效响应
2025-07-18 19:08:10,020 [WARNING] chat_llm: [ERR] 未生成有效结果
2025-07-18 19:08:10,025 [INFO] chat_llm: 处理完成: C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:08:10,025 [INFO] __main__: 处理完成，用时: 0.73秒
2025-07-18 19:08:47,787 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:08:47,787 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer']
2025-07-18 19:08:47,787 [INFO] chat_llm: 初始化ChatLLM，URL: https://api.deepseek.com
2025-07-18 19:08:47,787 [INFO] chat_llm: Prompt Keys: ['generate_assistant_new']
2025-07-18 19:08:47,787 [INFO] chat_llm: Response Processors: ['no_think_response_processor']
2025-07-18 19:08:47,828 [INFO] __main__: 开始处理: C:\\开源代码\\LLMCall\\data\\input.jsonl -> C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:08:47,860 [INFO] chat_llm: 开始处理文件：C:\\开源代码\\LLMCall\\data\\input.jsonl
2025-07-18 19:08:48,312 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,313 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,313 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,313 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,321 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,322 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,327 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,328 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,328 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:08:48,438 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:09:09,537 [INFO] chat_llm: 处理完成: C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:09:09,537 [INFO] __main__: 处理完成，用时: 21.71秒
2025-07-18 19:24:34,934 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:24:34,934 [ERROR] __main__: 执行失败: module 'response_processor' has no attribute 'simple_reponse_processor'
Traceback (most recent call last):
  File "C:\开源代码\LLMCall\main.py", line 202, in main
    chat_llm = init_chat_llm()
  File "C:\开源代码\LLMCall\main.py", line 89, in init_chat_llm
    group_processors = [getattr(response_processor, name) for name in group]
  File "C:\开源代码\LLMCall\main.py", line 89, in <listcomp>
    group_processors = [getattr(response_processor, name) for name in group]
AttributeError: module 'response_processor' has no attribute 'simple_reponse_processor'. Did you mean: 'simple_response_processor'?
2025-07-18 19:24:53,961 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:24:53,962 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer_1_1', 'answer1_2', 'answer2_1']
2025-07-18 19:24:53,962 [INFO] chat_llm: 初始化ChatLLM（分组模式），URL: https://api.deepseek.com
2025-07-18 19:24:53,962 [INFO] chat_llm: Prompt Keys: ['generate_assistant_new', 'tmp']
2025-07-18 19:24:53,962 [INFO] chat_llm: 分组数量: 2
2025-07-18 19:24:53,962 [INFO] chat_llm: 第1组处理器: ['no_think_response_processor', 'simple_response_processor']
2025-07-18 19:24:53,962 [INFO] chat_llm: 第2组处理器: ['no_think_response_processor']
2025-07-18 19:24:54,008 [INFO] __main__: 开始处理: C:\\开源代码\\LLMCall\\data\\input.jsonl -> C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:24:54,040 [INFO] chat_llm: 开始处理文件：C:\\开源代码\\LLMCall\\data\\input.jsonl
2025-07-18 19:24:54,539 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,541 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,542 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,545 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,586 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,605 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,607 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,608 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,608 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:24:54,662 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:08,825 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:09,601 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:14,410 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:15,895 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:15,907 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:17,631 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:17,890 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:18,639 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:18,735 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:22,085 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:25:49,971 [INFO] chat_llm: 处理完成: C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:25:49,972 [INFO] __main__: 处理完成，用时: 55.96秒
2025-07-18 19:29:23,737 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:29:23,737 [INFO] dataset_config: 数据集配置: ['session', 'query'] -> ['answer_1_1', 'answer1_2', 'answer2_1']
2025-07-18 19:29:23,737 [INFO] chat_llm: 初始化ChatLLM（分组模式），URL: https://api.deepseek.com
2025-07-18 19:29:23,737 [INFO] chat_llm: Prompt Keys: ['generate_assistant_new', 'tmp']
2025-07-18 19:29:23,737 [INFO] chat_llm: 分组数量: 2
2025-07-18 19:29:23,737 [INFO] chat_llm: 第1组处理器: ['no_think_response_processor', 'test_respoonse_processor']
2025-07-18 19:29:23,740 [INFO] chat_llm: 第2组处理器: ['no_think_response_processor']
2025-07-18 19:29:23,790 [INFO] __main__: 开始处理: C:\\开源代码\\LLMCall\\data\\input.jsonl -> C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:29:23,823 [INFO] chat_llm: 开始处理文件：C:\\开源代码\\LLMCall\\data\\input.jsonl
2025-07-18 19:29:24,360 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,385 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,390 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,391 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,392 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,398 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,404 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,405 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,493 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:24,496 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:38,474 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:39,123 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:41,048 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:41,490 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:44,827 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:44,850 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:47,507 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:48,395 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:48,748 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:29:49,412 [INFO] httpx: HTTP Request: POST https://api.deepseek.com/chat/completions "HTTP/1.1 200 OK"
2025-07-18 19:30:17,337 [INFO] chat_llm: 处理完成: C:\\开源代码\\LLMCall\\data\\output.jsonl
2025-07-18 19:30:17,339 [INFO] __main__: 处理完成，用时: 53.55秒
2025-07-18 19:31:49,534 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:31:49,535 [ERROR] __main__: 执行失败: 分组模式下，RESPONSE_PROCESSOR分组数量(1)必须与PROMPT_KEY数量(2)相同
Traceback (most recent call last):
  File "C:\开源代码\LLMCall\main.py", line 202, in main
    chat_llm = init_chat_llm()
  File "C:\开源代码\LLMCall\main.py", line 71, in init_chat_llm
    raise ValueError(f"分组模式下，RESPONSE_PROCESSOR分组数量({len(grouped_response_processors)})必须与PROMPT_KEY数量({len(prompt_keys)})相同")
ValueError: 分组模式下，RESPONSE_PROCESSOR分组数量(1)必须与PROMPT_KEY数量(2)相同
2025-07-18 19:32:01,948 [INFO] __main__: 日志初始化完成: log/log.txt
2025-07-18 19:32:01,949 [ERROR] __main__: 执行失败: 分组模式下，OUTPUT_COLUMN分组数量(1)必须与PROMPT_KEY数量(2)相同
Traceback (most recent call last):
  File "C:\开源代码\LLMCall\main.py", line 202, in main
    chat_llm = init_chat_llm()
  File "C:\开源代码\LLMCall\main.py", line 74, in init_chat_llm
    raise ValueError(f"分组模式下，OUTPUT_COLUMN分组数量({len(grouped_output_columns)})必须与PROMPT_KEY数量({len(prompt_keys)})相同")
ValueError: 分组模式下，OUTPUT_COLUMN分组数量(1)必须与PROMPT_KEY数量(2)相同
